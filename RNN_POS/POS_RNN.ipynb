{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.9 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        }
      }
    },
    "colab": {
      "name": "POS_RNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P6phKzEcEDT"
      },
      "source": [
        "## Loading essential libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAkP62SNcEDc"
      },
      "source": [
        "# import necessary libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from nltk.corpus import brown\n",
        "from nltk.corpus import treebank\n",
        "from nltk.corpus import conll2000\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l1Dg-L3e0QY"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSjMuzPFe2I9",
        "outputId": "6221e817-a9d9-4307-d223-2035c976b069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('universal_tagset')\r\n",
        "nltk.download('treebank')\r\n",
        "nltk.download('brown')\r\n",
        "nltk.download('conll2000')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ2FzIOzcEDd"
      },
      "source": [
        "## Preprocess Data\n",
        "Using POS Tagged Corpora from NLTK\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PL5iw6fcEDe"
      },
      "source": [
        "# load POS tagged corpora from NLTK\n",
        "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
        "brown_corpus = brown.tagged_sents(tagset='universal')\n",
        "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
        "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQooYCtgcEDe",
        "outputId": "3c645943-a668-483c-fc2a-23164ad4a636",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tagged_sentences[7]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A', 'DET'),\n",
              " ('Lorillard', 'NOUN'),\n",
              " ('spokewoman', 'NOUN'),\n",
              " ('said', 'VERB'),\n",
              " (',', '.'),\n",
              " ('``', '.'),\n",
              " ('This', 'DET'),\n",
              " ('is', 'VERB'),\n",
              " ('an', 'DET'),\n",
              " ('old', 'ADJ'),\n",
              " ('story', 'NOUN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfD7CWoReZbl"
      },
      "source": [
        "X = [] # store input sentence \r\n",
        "Y = [] # store input sentence "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akHOa5phekCy"
      },
      "source": [
        "for sentence in tagged_sentences:\r\n",
        "    X_sentence = []\r\n",
        "    Y_sentence = []\r\n",
        "    for entity in sentence:         \r\n",
        "        X_sentence.append(entity[0])  # entity[0] contains the word\r\n",
        "        Y_sentence.append(entity[1])  # entity[1] contains corresponding tag\r\n",
        "        \r\n",
        "    X.append(X_sentence)\r\n",
        "    Y.append(Y_sentence)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LkRa6eceqg-"
      },
      "source": [
        "num_words = len(set([word.lower() for sentence in X for word in sentence]))\r\n",
        "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dFrcK8oeumj",
        "outputId": "9fbc811a-06f4-4326-9fe7-399ad1ad5cda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Total number of tagged sentences: {}\".format(len(X)))\r\n",
        "print(\"Vocabulary size: {}\".format(num_words))\r\n",
        "print(\"Total number of tags: {}\".format(num_tags))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of tagged sentences: 72202\n",
            "Vocabulary size: 59448\n",
            "Total number of tags: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOCM2AA9eqoh",
        "outputId": "151241c1-49d3-4ea4-a8d0-05fb1b549df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# let's look at first data point\r\n",
        "# this is one data point that will be fed to the RNN\r\n",
        "print('sample X: ', X[0], '\\n')\r\n",
        "print('sample Y: ', Y[0], '\\n')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "sample Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtvQcJcRgXyU",
        "outputId": "bb911a96-5105-44dc-951b-0a7becb2f406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# In this many-to-many problem, the length of each input and output sequence must be the same.\r\n",
        "# Since each word is tagged, it's important to make sure that the length of input sequence equals the output sequence\r\n",
        "print(\"Length of first input sequence  : {}\".format(len(X[0])))\r\n",
        "print(\"Length of first output sequence : {}\".format(len(Y[0])))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of first input sequence  : 18\n",
            "Length of first output sequence : 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP_t7jzcgagZ"
      },
      "source": [
        "# encode X\r\n",
        "word_tokenizer = Tokenizer()                      # instantiate tokeniser\r\n",
        "word_tokenizer.fit_on_texts(X)                    # fit tokeniser on data\r\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)  # use the tokeniser to encode input sequence"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-kvXD444O0Y"
      },
      "source": [
        "# encode Y\r\n",
        "tag_tokenizer = Tokenizer()\r\n",
        "tag_tokenizer.fit_on_texts(Y)\r\n",
        "Y_encoded = tag_tokenizer.texts_to_sequences(Y)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUY_WV6D4Rv7",
        "outputId": "a121d5dd-ded8-49c4-f95b-ec994fc77598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# look at first encoded data point\r\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\r\n",
        "print('X: ', X[0], '\\n')\r\n",
        "print('Y: ', Y[0], '\\n')\r\n",
        "print()\r\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\r\n",
        "print('X: ', X_encoded[0], '\\n')\r\n",
        "print('Y: ', Y_encoded[0], '\\n')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [6423, 24231, 2, 7652, 102, 170, 2, 47, 1898, 1, 269, 17, 7, 13230, 619, 1711, 2761, 3] \n",
            "\n",
            "Y:  [1, 1, 3, 11, 1, 6, 3, 2, 2, 5, 1, 4, 5, 6, 1, 1, 11, 3] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgckLW-M4X_H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}