{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# POS_TAGGER\n",
    "## - step 1: Read and preprocess the dataset\n",
    "## - step 2: Build a Most Frequent Class (MFC) tagger to use as a       baseline\n",
    "## - step 3: Build an HMM POS Tagger\n",
    "## - step 4:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution\n",
    "import pandas as pd\n",
    "import sklearn as skl \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import defaultdict"
   ]
  },
  {
   "source": [
    "## Working with data file and create vocabulary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Read data file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"WSJ_02-21.pos\", 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [line.split('\\t')[0] for line in lines]\n",
    "# words"
   ]
  },
  {
   "source": [
    "### Create vocabulary file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = defaultdict(int)\n",
    "\n",
    "for word in words:\n",
    "    freq[word] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq['more']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = [k for k, v in freq.items() if (v > 1 and k != '\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary_file = open('vocabulary_file.txt', \"w+\")\n",
    "for i in vocabulary:\n",
    "    vocabulary_file = open('vocabulary_file.txt', \"a+\")\n",
    "    vocabulary_file.writelines(i + '\\n')\n",
    "# for i in range(0,10):\n",
    "#     print(vocabulary[i])"
   ]
  },
  {
   "source": [
    "### Processing new text sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### working words don't exist in the vocabulary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unknow(word):\n",
    "\n",
    "    #punctuation characters\n",
    "    punct = set(string.punctuation)\n",
    "\n",
    "    #suffixes\n",
    "    noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "    verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "    adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "    adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
    "    \n",
    "    if any(char.isdigit() for char in word):\n",
    "        return \"--unknow_digit--\"\n",
    "\n",
    "    elif any(char in punct for char in word):\n",
    "        return \"--unknow_punct--\"\n",
    "\n",
    "    elif any(char.isupper() for char in word):\n",
    "        return \"--unknow_upper\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unknow_noun--\" \n",
    "    \n",
    "    elif any(word.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unknow_verb--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unknow_adj--\"\n",
    "    \n",
    "    elif any(word.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unknow_adv--\"\n",
    "\n",
    "    return \"--unknow--\""
   ]
  },
  {
   "source": [
    "### Getting the correct tag for a word"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tag(line, vocabulary):\n",
    "    if not line.split():\n",
    "        word = \"--n--\"\n",
    "        tag = \"--s--\"\n",
    "    else:\n",
    "        word, tag = line.split()\n",
    "        if word not in vocabulary:\n",
    "            word = assign_unknow(word)\n",
    "\n",
    "    return word, tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_word_tag('\\n', vocabulary))\n",
    "print(get_word_tag('In\\tIN\\n', vocabulary))\n",
    "print(get_word_tag('tardigrade\\tNN\\n', vocabulary))\n",
    "print(get_word_tag('scrutinize\\tVB\\n', vocabulary))"
   ]
  },
  {
   "source": [
    "## Working with tags and Numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "### test with only 3 tags (RB, NN, TO)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = ['RB', 'NN', 'TO']"
   ]
  },
  {
   "source": [
    "### testing with transition_counts, which counts the number of times a particular tag happend next to another. The keys of dictionary have the form (previous_tag, tag) and the values are the frequency of occurrences. The trainsition_dictionary just works with tags only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example: define a transition_counts dictionary with random value:\n",
    "transition_counts = {\n",
    "    ('NN', 'NN'): 16241,\n",
    "    ('RB', 'RB'): 2263,\n",
    "    ('TO', 'TO'): 2,\n",
    "    ('NN', 'TO'): 5256,\n",
    "    ('RB', 'TO'): 855,\n",
    "    ('TO', 'NN'): 734,\n",
    "    ('NN', 'RB'): 2431,\n",
    "    ('RB', 'NN'): 358,\n",
    "    ('TO', 'RB'): 200\n",
    "}\n"
   ]
  },
  {
   "source": [
    "### Using numpy of matrix creation:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = len(tags)\n",
    "print(num_tags)\n",
    "\n",
    "transition_matrix = np.zeros((num_tags, num_tags))\n",
    "\n",
    "print(transition_matrix)\n",
    "print(transition_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_tags = sorted(tags)\n",
    "\n",
    "sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_tags):\n",
    "    for j in range(num_tags):\n",
    "        tag_tuple = (sorted_tags[i], sorted_tags[j])\n",
    "\n",
    "        transition_matrix[i, j] = transition_counts.get(tag_tuple)\n",
    "\n",
    "transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_transition_matrix(matrix):\n",
    "    print(pd.DataFrame(matrix, index = sorted_tags, columns = sorted_tags))\n",
    "\n",
    "print_transition_matrix(transition_matrix)"
   ]
  },
  {
   "source": [
    "### Working with Numpy for matrix manipulation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "rows_sum = transition_matrix.sum(axis = 1, keepdims = True)\n",
    "\n",
    "rows_sum"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# normalize the matrix \n",
    "rows_sum = transition_matrix.sum(axis = 1, keepdims = True)\n",
    "\n",
    "transition_matrix = transition_matrix / rows_sum\n",
    "\n",
    "print_transition_matrix(transition_matrix)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create rules use for unknown word\n",
    "\n",
    "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "adv_suffix = [\"ward\", \"wards\", \"wise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punct = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_unknow(word):\n",
    "\n",
    "    noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "    verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "    adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "    adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
    "\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return \"--unknow_digit--\"\n",
    "\n",
    "    elif any(char in punct for char in word):\n",
    "        return \"--unknow_punct--\"\n",
    "\n",
    "    elif any(char.isupper() for char in word):\n",
    "        return \"--unknow_upper--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unknow_noun--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unknow_verb--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unknow_adj--\"\n",
    "\n",
    "    elif any(word.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unknow_adv--\"\n",
    "\n",
    "    return \"--unknow--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tag(line, vocab):\n",
    "    if not line.split():\n",
    "        word = \"--n--\"\n",
    "        tag = \"--s--\"\n",
    "    else:\n",
    "        word, tag = line.split()\n",
    "        if word not in vocab:\n",
    "            word = assign_unknow(word)\n",
    "        return word, tag\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hmm_vocab.txt\", 'r') as f:\n",
    "    vocabulary = f.read().split('\\n')\n",
    "\n",
    "\n",
    "print(get_word_tag('\\n', vocabulary))\n",
    "print(get_word_tag('In\\tIN\\n', vocabulary))\n",
    "print(get_word_tag('tardigrade\\tNN\\n', vocabulary))\n",
    "print(get_word_tag('scrutinize\\tVB\\n', vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"WSJ_02-21.pos\", 'r') as f:\n",
    "    training_set = f.readlines()\n",
    "\n",
    "# print(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(vocab, data_fp):\n",
    "    \"\"\"\n",
    "    Preprocess data\n",
    "    \"\"\"\n",
    "    orig = []\n",
    "    prep = []\n",
    "\n",
    "    # Read data\n",
    "    with open(data_fp, \"r\") as data_file:\n",
    "\n",
    "        for cnt, word in enumerate(data_file):\n",
    "\n",
    "            # End of sentence\n",
    "            if not word.split():\n",
    "                orig.append(word.strip())\n",
    "                word = \"--n--\"\n",
    "                prep.append(word)\n",
    "                continue\n",
    "\n",
    "            # Handle unknown words\n",
    "            elif word.strip() not in vocab:\n",
    "                orig.append(word.strip())\n",
    "                word = assign_unknow(word)\n",
    "                prep.append(word)\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                orig.append(word.strip())\n",
    "                prep.append(word.strip())\n",
    "\n",
    "    assert(len(orig) == len(open(data_fp, \"r\").readlines()))\n",
    "    assert(len(prep) == len(open(data_fp, \"r\").readlines()))\n",
    "\n",
    "    return orig, prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary_with_index = {}\n",
    "\n",
    "for i, word in enumerate(sorted(vocabulary)):\n",
    "    vocabulary_with_index[word] = i\n",
    "\n",
    "# vocabulary_with_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"WSJ_24.pos\", 'r') as f:\n",
    "    test_set = f.readlines()\n",
    "\n",
    "for i in test_set:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, test_set_without_tag = preprocess(vocabulary_with_index, \"test.words\")\n",
    "print(test_set_without_tag[0:10])"
   ]
  },
  {
   "source": [
    "## Build MFC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Create 3 dictionaries:\n",
    " - transition dictionary: maps (prev_tag, tag) to the number of times it has appeared\n",
    " - emission_dictionary: maps (tag, word) to the number of times it happended\n",
    " - tag_dictionary: maps (tag) to the number of times it has occured "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pass into an training set and vocabulary then return 3 dictionaries above\n",
    "\n",
    "def create_dictionaries(training_set, vocabulary):\n",
    "    transition_dictionary = defaultdict(int)\n",
    "    emission_dictionary = defaultdict(int)\n",
    "    tag_dictionary = defaultdict(int)\n",
    "    \n",
    "    # define tag for the begining state (begining tag)\n",
    "    prev_tag = '--s--'\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for word_tag in training_set:\n",
    "        i += 1\n",
    "        \n",
    "        if i % 50000 == 0:\n",
    "            print(f\"word count = {i}\") \n",
    "\n",
    "        if word_tag == '\\n':\n",
    "            prev_tag = '--s--'\n",
    "            tag_dictionary['--s--'] += 1\n",
    "            continue\n",
    "\n",
    "        word, tag = get_word_tag(word_tag, vocabulary)\n",
    "\n",
    "        transition_dictionary[(prev_tag, tag)] += 1\n",
    "\n",
    "        emission_dictionary[(tag, word)] += 1\n",
    "\n",
    "        tag_dictionary[tag] += 1\n",
    "\n",
    "        prev_tag = tag\n",
    "\n",
    "    return transition_dictionary, emission_dictionary, tag_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_dictionary, emission_dictionary, tag_dictionary = create_dictionaries(training_set, vocabulary_with_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = sorted(tag_dictionary.keys())\n",
    "print('amount of states: ', len(states))\n",
    "print('list of states: ')\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(('--s--', 'IN'), 5050)\n(('IN', 'DT'), 32364)\n(('DT', 'NNP'), 9044)\n(('NNP', 'CD'), 1752)\n(('CD', 'NN'), 7377)\n(('NN', 'IN'), 32885)\n(('IN', '``'), 546)\n(('``', 'DT'), 1014)\n(('DT', 'NN'), 38873)\n(('NN', \"''\"), 686)\n"
     ]
    }
   ],
   "source": [
    "for ex in list(transition_dictionary.items())[:10]:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in list(emission_dictionary.items())[:10]:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, count in emission_dictionary.items():\n",
    "    if word[1] == 'review':\n",
    "        print(word, count) "
   ]
  },
  {
   "source": [
    "### Create predict function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_set_without_tag, test_set, emission_dictionary, vocabulary, states):\n",
    "    correct = 0\n",
    "\n",
    "    all_words = set(emission_dictionary.keys())\n",
    "\n",
    "    total = len(test_set)\n",
    "    for word, word_with_tag in zip(test_set_without_tag, test_set):\n",
    "        item = word_with_tag.split()\n",
    "\n",
    "        if len(item) == 2:\n",
    "            true_label = item[1]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        count_final = 0\n",
    "        pos_final = ''\n",
    "\n",
    "        if word in vocabulary:\n",
    "            for pos in states:\n",
    "                key = (pos, word)\n",
    "\n",
    "                if key in emission_dictionary:\n",
    "                    count = emission_dictionary[key]\n",
    "\n",
    "                    if count > count_final:\n",
    "                        count_final = count\n",
    "                        pos_final = pos\n",
    "            if pos_final == true_label:\n",
    "                correct += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8888563993099213\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict(test_set_without_tag, test_set, emission_dictionary, vocabulary_with_index, states)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}